{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ad40699",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'Dataset2Vec'...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloned repository into ./Dataset2Vec\n"
     ]
    }
   ],
   "source": [
    "import sys, subprocess, importlib, os\n",
    "REPO_URL = \"https://github.com/khayhamz31/d2v_copy\"\n",
    "REPO_DIR = \"Dataset2Vec\"\n",
    "\n",
    "if not os.path.exists(REPO_DIR):\n",
    "    subprocess.run(\n",
    "        [\"git\", \"clone\", \"--depth\", \"1\", REPO_URL, REPO_DIR],\n",
    "        check=True\n",
    "    )\n",
    "    print(f\"Cloned repository into ./{REPO_DIR}\")\n",
    "else:\n",
    "    print(\"dataset2vec already present in project root.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa2812d",
   "metadata": {},
   "source": [
    "### Environment Imports  \n",
    "Core libraries, OpenML access, widgets for UI, and project modules for:\n",
    "- downloading datasets  \n",
    "- extracting traditional & D2V meta-features  \n",
    "- aggregating runs  \n",
    "- training meta-classifier and meta-regressor models  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760030fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import openml\n",
    "import ipywidgets as widgets\n",
    "import time\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output, display\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "# SET OPENML KEY HERE \n",
    "openml.config.apikey = \"\"\n",
    "from datasets import (\n",
    "    download_benchmark_suite,\n",
    "    download_and_process_dataset,\n",
    "    download_datasets_from_df\n",
    ")\n",
    "\n",
    "from qualities import extract_metafeatures_from_local_datasets\n",
    "\n",
    "from d2v_qualities import extract_metafeatures_from_datasets\n",
    "\n",
    "from runs import run_pipeline\n",
    "\n",
    "from metaclassifier import run_meta_classifier\n",
    "\n",
    "from metaregressor import run_meta_regressor_multioutput\n",
    "\n",
    "from regressor_comparison import plot_regressor_as_classifier_results\n",
    "\n",
    "# set random seed for reproducibility\n",
    "random_seed = 411"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7293fc60",
   "metadata": {},
   "source": [
    "### Benchmark Suite Selection  \n",
    "Fetch OpenML benchmark suites with retry logic, display a dropdown selector, and download datasets from the chosen suite "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6739ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_retries = 3\n",
    "delay = 5\n",
    "\n",
    "for attempt in range(max_retries):\n",
    "    try:\n",
    "        suites_df = openml.study.list_suites(output_format=\"dataframe\", status=\"all\")\n",
    "        break\n",
    "    except openml.exceptions.OpenMLServerException:\n",
    "        if attempt < max_retries - 1:\n",
    "            time.sleep(delay)\n",
    "        else:\n",
    "            raise RuntimeError(\"Failed to fetch benchmark suites after multiple retries.\")\n",
    "\n",
    "suites_df[\"alias\"] = suites_df[\"alias\"].fillna(\"unnamed\")\n",
    "options = [(f\"{alias} ({sid})\", sid) for sid, alias in zip(suites_df[\"id\"], suites_df[\"alias\"])]\n",
    "\n",
    "dropdown = widgets.Dropdown(\n",
    "    options=options,\n",
    "    description='Suite:',\n",
    "    layout=widgets.Layout(width='60%')\n",
    ")\n",
    "output = widgets.Output()\n",
    "selected_suite_info = {\"id\": None, \"alias\": None}\n",
    "\n",
    "def on_dropdown_change(change):\n",
    "    if change[\"type\"] == \"change\" and change[\"name\"] == \"value\":\n",
    "        with output:\n",
    "            clear_output()\n",
    "            sid = change[\"new\"]\n",
    "            alias = next(label.split(\" (\")[0] for label, val in options if val == sid)\n",
    "            selected_suite_info.update({\"id\": sid, \"alias\": alias})\n",
    "            print(f\"Downloading: {alias} ({sid})...\")\n",
    "            res = download_benchmark_suite(sid)\n",
    "            print(f\"{res['successful']}/{res['total']} downloaded, {res['failed']} failed.\")\n",
    "\n",
    "dropdown.observe(on_dropdown_change)\n",
    "display(dropdown, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5721b2",
   "metadata": {},
   "source": [
    "### Meta-feature extraction \n",
    "1. Extracts meta-features from openml for the datasets downloaded\n",
    "2. Extracts Dataset2Vec meta-features from the datasets downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac55b32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_local = extract_metafeatures_from_local_datasets(\"test_datasets\")\n",
    "stats = extract_metafeatures_from_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f150c0",
   "metadata": {},
   "source": [
    "### Meta-target extraction\n",
    "1. Downloads and samples run data from OpenML for the datasets downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35740993",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_pipeline(\n",
    "    mapping_path=\"test_datasets/id_task_mapping.json\",\n",
    "    flow_map_path=\"flows/filtered_flow_algorithm_mapping_v2.json\",\n",
    "    sample_size=50,\n",
    "    batch_size=50,\n",
    "    base_dir=\"runs\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cec948b",
   "metadata": {},
   "source": [
    "### Meta-classifier\n",
    "1. Trains meta-classifier \n",
    "2. Evaluates meta-classifier performance (LOOCV with n_repeats)\n",
    "3. Visualises with boxplot and simple statistics (mean accuracy Â± std )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd89fc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "results, majority_acc, summary, (fig, ax) = run_meta_classifier(\n",
    "    # choosing performance metrics (accuracy or f1)\n",
    "    metric_name=\"accuracy\",\n",
    "    # change for algorithm subsets ['decision_tree','random_forest','xgboost','linear_models','support_vector_machine'] or None for all \n",
    "    algorithms=['decision_tree','random_forest','xgboost'],\n",
    "    # change number of repeats (numer of meta-models)\n",
    "    n_repeats=10,\n",
    "    # Change random seed for reproducibility\n",
    "    seed = random_seed,\n",
    "    # Change title for plot\n",
    "    plot_title=\"Benchmark Suite 99 (Classifier)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f9da08",
   "metadata": {},
   "source": [
    "### Meta-Regressor \n",
    "1. Trains the meta-regressor  \n",
    "2. Evaluates meta-regressor performance (LOO-CV with n_repeats)\n",
    "3. Saves simple statistics and predictions to the results folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c11c620",
   "metadata": {},
   "outputs": [],
   "source": [
    "results, baseline_mae, summary_df = run_meta_regressor_multioutput(\n",
    "    # choosing performance metrics (accuracy or f1)\n",
    "    metric_name=\"accuracy\",\n",
    "    # change for algorithm subsets ['decision_tree','random_forest','xgboost','linear_models','support_vector_machine'] or None for all\n",
    "    algorithms=None,\n",
    "    # change number of repeats (numer of meta-models)\n",
    "    n_repeats=10,\n",
    "    # change random seed for reproducibility\n",
    "    seed = random_seed,\n",
    "    # change folder to save regressor results\n",
    "    output_dir=\"meta_regressor_results\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d009449",
   "metadata": {},
   "source": [
    "### Meta-regressor as classifier  \n",
    "Uses meta-regressor outputs to visualises them in the same format as the meta-classifier for direct comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e67492",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies, majority_accuracy, summary_df, (fig, ax) = plot_regressor_as_classifier_results(\n",
    "    # change to where meta_regressor results are stored\n",
    "    analysis_csv=\"meta_regressor_results/analysis/top1_accuracy_analysis.csv\",\n",
    "    # change folder to save regressor as classifier\n",
    "    output_dir=\"regresscompress\",\n",
    "    # Change title for plot\n",
    "    plot_title=\"Benchmark Suite 99 (Regressor)\",\n",
    "    ylabel=\"Mean Accuracy\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.24"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
